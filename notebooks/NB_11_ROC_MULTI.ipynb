{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maestría en Maestría en Ciencia de Datos e Inteligencia Artificial\n",
    "#### 8. Machine Learning and Deep Learning\n",
    "#### Docente: Msc. Renzo Claure Aracena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "cancer = pd.read_csv('cancer.csv', delimiter = \";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.drop(['Tipo', 'ID'], axis=1)\n",
    "y = cancer['Tipo'].replace(['M', 'B'], [1,0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score de Clasificacion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lr = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, lr_pred)\n",
    "confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "y_scores_lr = lr.decision_function(X_test)\n",
    "lr_pred = lr.predict(X_test)\n",
    "y_score_list = list(zip(y_test[0:20], lr_pred[0:20], y_scores_lr[0:20]))\n",
    "\n",
    "y_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Probabilidad de Clasificacion\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "y_proba_lr = lr.fit(X_train, y_train).predict_proba(X_test)\n",
    "y_proba_list = list(zip(y_test[0:20], lr_pred[0:20], y_proba_lr[0:20,1]))\n",
    "\n",
    "\n",
    "y_proba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva Precision Recall\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, umbral = precision_recall_curve(y_test, y_scores_lr)\n",
    "cercano_cero = np.argmin(np.abs(umbral))\n",
    "cercano_cero_p = precision[cercano_cero]\n",
    "cercano_cero_r = recall[cercano_cero]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.plot(precision, recall, label='Precision-Recall Curva')\n",
    "plt.plot(cercano_cero_p, cercano_cero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n",
    "plt.xlabel('Precision', fontsize=16)\n",
    "plt.ylabel('Recall', fontsize=16)\n",
    "#plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curva ROC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "y_score_rl = lr.fit(X_train, y_train).decision_function(X_test)\n",
    "fpr_rl, tpr_rl, _ = roc_curve(y_test, y_score_rl)\n",
    "roc_auc_rl = auc(fpr_rl, tpr_rl)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr_rl, tpr_rl, lw=3, label='Regresion Log ROC (area = {:0.2f})'.format(roc_auc_rl))\n",
    "plt.xlabel('Falsos Positivos R.', fontsize=16)\n",
    "plt.ylabel('Verdaderos Positivos R.', fontsize=16)\n",
    "plt.title('ROC curva Cancer', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=3, linestyle='--')\n",
    "#plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC para comparar más de un modelo\n",
    "%matplotlib inline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.xlim([-0.01, 1])\n",
    "plt.ylim([-0.01, 1])\n",
    "for gi in [0.001, 0.1, 0.2, 0.5, 1 ]:\n",
    "    svm = SVC(gamma =gi ).fit(X_train, y_train)\n",
    "    y_score = svm.decision_function(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    accuracy = svm.score(X_test, y_test)\n",
    "    print('Gamma: {:.3f}  Accuracy: {:.3f} Auc: {:.3f}'.format(gi, accuracy, roc_auc))\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.5, label='SVM (gamma = {:0.3f}, area = {:0.3f})'.format(gi, roc_auc))\n",
    "\n",
    "plt.xlabel('Ratio Falsos Positivos', fontsize=16)\n",
    "plt.ylabel('Ratio Verdaderos Positivos  (Recall)', fontsize=16)\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=0.5, linestyle='--')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.title('ROC :(Cancer)', fontsize=16)\n",
    "#plt.axes().set_aspect('equal')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de modelos de clasificación multinivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación pseudidicotómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('COMPRA DE PRODUCTOS.csv', delimiter=\";\", decimal=',')\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('COMPRA DE PRODUCTOS.csv', delimiter=\";\", decimal=',')\n",
    "X, y = base.drop(['ID', 'GRUPO_PRODUCTO', 'CON_LINEA_CREDITO'], axis=1), base['GRUPO_PRODUCTO']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(X, y, random_state=0)\n",
    "\n",
    "svm = SVC(kernel = 'linear').fit(X_train_mc, y_train_mc)\n",
    "svm_predicted_mc = svm.predict(X_test_mc)\n",
    "confusion_mc = confusion_matrix(y_test_mc, svm_predicted_mc)\n",
    "df_cm = pd.DataFrame(confusion_mc, \n",
    "                     index = [i for i in range(0,4)], columns = [i for i in range(0,4)])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.0f')\n",
    "plt.title('SVM Kernel Lineal \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test_mc, \n",
    "                                                                       svm_predicted_mc)))\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Prediccion')\n",
    "\n",
    "\n",
    "svm = SVC(kernel = 'rbf').fit(X_train_mc, y_train_mc)\n",
    "svm_predicted_mc = svm.predict(X_test_mc)\n",
    "confusion_mc = confusion_matrix(y_test_mc, svm_predicted_mc)\n",
    "df_cm = pd.DataFrame(confusion_mc, index = [i for i in range(0,4)],\n",
    "                  columns = [i for i in range(0,4)])\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"BuPu\")\n",
    "plt.title('SVM Kernel RBF \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test_mc, \n",
    "                                                                    svm_predicted_mc)))\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Prediccion');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.0f', cmap=\"BuPu\")\n",
    "plt.title('SVM Kernel Lineal \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test_mc, \n",
    "                                                                       svm_predicted_mc)))\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Prediccion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_mc, svm_predicted_mc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macro y Micro precisión, recall y F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Micro precision: {:.2f}'.format(precision_score(y_test_mc, svm_predicted_mc, average='micro')))\n",
    "print('Macro precision: {:.2f}'.format(precision_score(y_test_mc, svm_predicted_mc, average='macro')))\n",
    "print('Micro recall: {:.2f}'.format(recall_score(y_test_mc, svm_predicted_mc, average='micro')))\n",
    "print('Macro recall: {:.2f}'.format(recall_score(y_test_mc, svm_predicted_mc, average='macro')))\n",
    "print('Micro F1: {:.2f}'.format(f1_score(y_test_mc, svm_predicted_mc, average='micro')))\n",
    "print('Macro F1: {:.2f}'.format(f1_score(y_test_mc, svm_predicted_mc, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realicen el mismo ejercicio con árboles de desición**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
