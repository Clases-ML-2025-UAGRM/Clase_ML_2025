{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maestría en CIENCIAS DE DATOS Y BIG DATA V1E4\n",
    "#### 09. MACHINE LEARNING: APRENDIZAJE SUPÉRVISADO\n",
    "#### Docente: Msc. Renzo Claure Aracena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGERESIÓN LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "plt.figure()\n",
    "plt.title('Muestra de regresion simple')\n",
    "X_R1, y_R1 = make_regression(n_samples = 100, n_features=1,\n",
    "                            n_informative=1, bias = 150.0,\n",
    "                            noise = 30, random_state=0)\n",
    "plt.scatter(X_R1, y_R1, marker= 'o', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1, random_state=0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('modelo lineal coef B: {}'.format(linreg.coef_))\n",
    "print('modelo lineal interseccion Bo: {}'.format(linreg.intercept_))\n",
    "print('modelo lineal exactitud entrenamiento: {}'.format(linreg.score(X_train, y_train)))\n",
    "print('modelo lineal exactitud comprobación: {}'.format(linreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico lineal con líne de tendencia ajustada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(X_R1, y_R1, marker='o', s=50, alpha=0.8)\n",
    "plt.plot(X_R1, linreg.intercept_ + linreg.coef_*X_R1, 'r-')\n",
    "plt.title('Regresion lineal con Minimos Cuadrados')\n",
    "plt.xlabel('Var. Independiente X')\n",
    "plt.ylabel('Var. Objetivo y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_distribucion (ROJO, AZUL, ROJO_N, AZUL_N, Titulo):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    ax1 = sn.distplot(ROJO, hist=False, color=\"b\", label=ROJO_N)\n",
    "    ax2 = sn.distplot(AZUL, hist=False, color=\"r\", label=AZUL_N, ax=ax1)\n",
    "\n",
    "    plt.title(Titulo)\n",
    "    plt.xlabel('y (Target)')\n",
    "    plt.ylabel('Proporcion de casos')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = linreg.predict(X_train)\n",
    "Titulo = 'Curva de Distribución Entrenamiento'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "funcion_distribucion(y_train, y_pred_train, \"Valores_reales_Entren\", \"Valores_predichos_Entren\", Titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_est = linreg.predict(X_test)\n",
    "Titulo = 'Curva de Distribución Comprobación'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "funcion_distribucion(y_test, y_pred_est, \"Valores_reales_Compr\", \"Valores_predichos_Compr\", Titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston = data\n",
    "y_boston = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_boston, y_boston, test_size=0.3, random_state = 0)\n",
    "\n",
    "linridge = Ridge(alpha=2.0).fit(X_train, y_train)\n",
    "\n",
    "print('Datos boston')\n",
    "print('Modelo de Regresion regularizada RIDGE, INTERSECCION: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('Modelo de Regresion regularizada RIDGE, pendiente:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-cuadrado score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train, y_train)))\n",
    "print('R-cuadrado score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_boston, y_boston, test_size=0.3,  random_state = 0)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scaler = scaler.transform(X_train) # generando la normalizacion a partir del entrenamiento\n",
    "X_test_scaler = scaler.transform(X_test) \n",
    "\n",
    "linridge =  Ridge(alpha=2).fit(X_train_scaler, y_train)\n",
    "\n",
    "print('Datos boston')\n",
    "print('Modelo de Regresion regularizada RIDGE, intercsion: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('Modelo de Regresion regularizada RIDGE, pendiente:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-cuadrado score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaler, y_train)))\n",
    "print('R-cuadrado score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaler, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efecto de la eleccion de alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha_i in [0.0001, 0.001, 0.01, 0, 1, 2, 3, 4, 5, 20]:\n",
    "    linridge = Ridge(alpha=alpha_i).fit(X_train_scaler, y_train)\n",
    "    r2_train = linridge.score(X_train_scaler, y_train)\n",
    "    r2_test = linridge.score(X_test_scaler, y_test)\n",
    "    num_efec_gr = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    print('Alpha = {:.4f}\\nnum abs(coeff) > 1.0: {}, \\r-cuadrado entrenamiento: {:.2f}, r-cuadrado comprobacion: {:.2f}\\n'.format(alpha_i, num_efec_gr, r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_boston, y_boston, test_size=0.3, random_state = 0)\n",
    "\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)\n",
    "\n",
    "linlasso = Lasso(alpha=0.1, max_iter = 10000).fit(X_train_scaler, y_train)\n",
    "\n",
    "print('Regresion Laso ML interseccion: {}'\n",
    "     .format(linlasso.intercept_))\n",
    "print('Regresion Laso ML efecto:\\n{}'\n",
    "     .format(linlasso.coef_))\n",
    "print('Efectos <> cero: {}'\n",
    "     .format(np.sum(linlasso.coef_ != 0)))\n",
    "print('R-cuadrado score (entrenamiento): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaler, y_train)))\n",
    "print('R-cuadrado score (comprobación): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaler, y_test)))\n",
    "print('Efectos <> cero transformados :')\n",
    "\n",
    "for e in sorted (list(zip(list(X_boston), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 15\n",
    "x = np.linspace(0,10,n) + np.random.randn(n)/5\n",
    "y = np.sin(x)+x/6 + np.random.randn(n)/10\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "#Para dibujar un scatterplot\n",
    "def scatter():\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train, y_train, label='Entrenamiento')\n",
    "    plt.scatter(X_test, y_test, label='Comprobacion')\n",
    "    plt.legend(loc=4);\n",
    "\n",
    "scatter()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "plt.figure()\n",
    "plt.title('Regresión compleja')\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)\n",
    "\n",
    "plt.scatter(X_F1[:, 4], y_F1, marker= 'o', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_F1, y_F1, random_state = 0)\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('ML (modelo lineal) efecto (b): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('ML interseccion (a): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('R-cuadrado score (entrenamiento): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-cuadrado score (comprobacion): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\nAdicion de nuevos efectos polinómicos, grado 2 o cuadratico )\\n')\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_F1_poly = poly.fit_transform(X_F1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1, random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('(poly deg 2) ML efecto (b):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly deg 2) ML interseccion (a): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly deg 2) R-squared score (entrenamiento): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2) R-squared score (comprobacion): {:.3f}\\n'\n",
    "     .format(linreg.score(X_test, y_test)))\n",
    "\n",
    "print('\\nEl increneto de nuevas variables polinómicas \\n\\\n",
    "mejora la precisión, pero reduce la generalizacion\\n\\\n",
    "po lo que deben utilizarse en conjunto regularizaciones como RIDGE\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1,\n",
    "                                                   random_state = 0)\n",
    "linreg = Ridge(alpha=1).fit(X_train, y_train)\n",
    "\n",
    "print('(poly grado 2 + ridge) ML efecto (b):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly grado 2 + ridge) ML interseccion (a): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly grado 2 + ridge) R-cuadrado score (entrenamiento): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly grado 2 + ridge) R-cuadrado score (comprobacion): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "Input=[('scale',MinMaxScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',Ridge())]\n",
    "pipe=Pipeline(Input)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de datos de Boston, realice un modelo lineal, polinomico de grado 2, con regularizacion Ridge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
